{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adding new objects to the main PCAReady and classlist files\n",
    "\n",
    "Takes an input csv file holding the parameters of the objects to be included plus a folder containing the new spectra. It then processes these along the lines of the previous objects and then includes them in the main PCAReady and classlist files. It rejects duplicates.\n",
    "\n",
    "**Requires the same _functions.py_ as used for the main PCAReady.txt**\n",
    "\n",
    "### Notes:\n",
    "For convenience, you may want to run this in its own folder, copying functions.py over as you do. The new object PCA/Classlist are saved in a ./PCAReady/ folder created in this directory, but the final save folder can be specfied to be your main PCAReady folder.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "from functions import dered, z_range, target_wavelength_range, ProcessSpectra\n",
    "import matplotlib.pyplot as plt\n",
    "from glob import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## These are the user defined parameters\n",
    "1) __new_obj_csv__ is the the csv file containing the information for the new objects\n",
    "\n",
    "2) __extension__ is the extension given to the PCAReady and classlist files associated with the new objects, these will eventually be concatenated with the main PCAReady file.\n",
    "\n",
    "3) __save__ is a boolean which determines whether the intermediate PCAReady file is saved. Set to False for debugging.\n",
    "\n",
    "4) __ref_PCA__ and __ref_classlist__ are the physical locations of the main PCAReady and classlist files.\n",
    "\n",
    "5) __ext__ is the extension for the final PCAReady/classlist files in the form e.g., PCAReady.\\<ext\\>.txt\n",
    "\n",
    "6) __final_save_folder__ is the destination folder for the final PCAReady/classlist files\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the input CSV file and the extension for the PCAReady/classlist file output\n",
    "new_obj_csv = 'new_objects.csv'\n",
    "extension = ''\n",
    "\n",
    "# Save PCAready file for the new objects? Set to False for debugging.\n",
    "save = False\n",
    "\n",
    "# main PCAready and classlist files (inc. location) to concatenate to\n",
    "ref_PCA = ''\n",
    "ref_classlist = ''\n",
    "\n",
    "# define the extension of the concatenated PCAReady and classlist files, along with the save location of these files\n",
    "ext = ''\n",
    "final_save_folder = './PCA_ready'\n",
    "\n",
    "##################### This just loads the csv\n",
    "\n",
    "new_objects = pd.read_csv(f'./{new_obj_csv}', delim_whitespace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-processing of the spectra to get them ready for PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SN2009dc_2009-04-16_00-00-00_TNG_DOLORES_None.ascii\n",
      "SN2009dc_2009-04-17_00-00-00_NOT_ALFOSC_None.ascii\n",
      "SN2009dc_2009-04-18_00-00-00_NOT_ALFOSC_None.ascii\n",
      "SN2009dc_2009-04-22_00-00-00_NOT_ALFOSC_None.ascii\n",
      "SN2009dc_2009-04-28_00-00-00_CA-2.2m_CAFOS_None.ascii\n",
      "SN2009dc_2009-04-30_00-00-00_CA-2.2m_CAFOS_None.ascii\n",
      "SN2009dc_2009-05-02_00-00-00_TNG_DOLORES_None.ascii\n",
      "SN2009dc_2009-05-03_00-00-00_CA-2.2m_CAFOS_None.ascii\n",
      "SN2009dc_2009-05-05_00-00-00_NOT_ALFOSC_None.ascii\n",
      "SN2009dc_2009-05-07_00-00-00_NOT_ALFOSC_None.ascii\n",
      "SN2009dc_2009-05-08_00-00-00_NOT_ALFOSC_None.ascii\n",
      "SN2009dc_2009-05-13_00-00-00_TNG_DOLORES_None.ascii\n",
      "SN2009dc_2009-05-18_00-00-00_ESO-NTT_EFOSC2-NTT_None.ascii\n",
      "SN2009dc_2009-05-28_00-00-00_Ekar_AFOSC_None.ascii\n",
      "SN2009dc_2009-06-01_00-00-00_CA-2.2m_CAFOS_None.ascii\n",
      "SN2009dc_2009-06-20_00-00-00_TNG_DOLORES_None.ascii\n",
      "SN2009dc_2009-06-27_00-00-00_CA-2.2m_CAFOS_None.ascii\n",
      "SN2009dc_2009-07-15_00-00-00_ESO-NTT_EFOSC2-NTT_None.ascii\n",
      "SN2009dc_2009-08-02_00-00-00_CA-2.2m_CAFOS_None.ascii\n",
      "SN2009dc_2009-08-31_00-00-00_CA-2.2m_CAFOS_None.ascii\n",
      "SN2009dc_2009-10-08_00-00-00_CA-2.2m_CAFOS_None.ascii\n"
     ]
    }
   ],
   "source": [
    "def cut_spectrum(x, y, lo, high):\n",
    "    '''\n",
    "    Cuts a spectrum to certain wavelength limits\n",
    "    '''\n",
    "    \n",
    "    lo_cut = np.argmin(abs(x - lo))\n",
    "    high_cut = np.argmin(abs(x - high))\n",
    "    x = x[lo_cut: high_cut + 1]\n",
    "    y = y[lo_cut: high_cut + 1]\n",
    "    \n",
    "    return np.array(x), np.array(y)\n",
    "\n",
    "\n",
    "def process_spectrum(sn = '', sn_class = 'UNK', E = 1e-5, z = 0, t = 0, dst = 'new_spectra', f = '',\n",
    "                     low_cut = 0, high_cut = 10000 ):\n",
    "    '''Process the observed spectra for each object by cutting to a required wavelength range,\n",
    "    correcting for E(B-V), and redshift.\n",
    "    Saves in the appropriate format for PCA processing.\n",
    "    '''\n",
    "        \n",
    "    if os.path.isfile(f) == False:\n",
    "        print(f'{f} does not exist, skpping')\n",
    "        \n",
    "        return None\n",
    "    \n",
    "    \n",
    "    x,y = np.loadtxt(f, unpack = True, usecols = (0,1) )\n",
    "        \n",
    "    x, y = cut_spectrum(x, y, low_cut, high_cut)\n",
    "        \n",
    "    y = dered(x, y , 3.1, E)\n",
    "        \n",
    "    x = x / (1 + z)\n",
    "        \n",
    "    plt.plot(x,y)\n",
    "        \n",
    "    print(os.path.basename(f))\n",
    "        \n",
    "    m = list(zip(x,y))\n",
    "        \n",
    "    savename = f'{sn_class}_{sn}_{t:.2f}_.txt'\n",
    "    \n",
    "    if os.path.isdir(f'./{dst}') == False:\n",
    "        print(f'Creating ./{dst}')\n",
    "        os.mkdir(f'./{dst}')\n",
    "    \n",
    "    np.savetxt(f'./{dst}/{savename}', m, fmt = \"%s\" )\n",
    "    plt.savefig(f'./{dst}/{savename}.pdf')\n",
    "    plt.close()\n",
    "        \n",
    "             \n",
    "\n",
    "for idx, row in new_objects.iterrows():\n",
    "\n",
    "    process_spectrum(sn = row.SN, sn_class = row.classification, z = float(row.z), t = float(row.t), \n",
    "                     E = float(row.E), f = row.file, low_cut = row.low_cut, high_cut = row.high_cut)     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process the spectra for the PCA and save the classlist and PCAReady file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/21 Processing Ia-SupCh_SN2009dc_126.20_.txt \n",
      "2/21 Processing Ia-SupCh_SN2009dc_35.40_.txt \n",
      "3/21 Processing Ia-SupCh_SN2009dc_7.30_.txt \n",
      "4/21 Processing Ia-SupCh_SN2009dc_11.40_.txt \n",
      "5/21 Processing Ia-SupCh_SN2009dc_61.30_.txt \n",
      "6/21 Processing Ia-SupCh_SN2009dc_54.40_.txt \n",
      "7/21 Processing Ia-SupCh_SN2009dc_97.20_.txt \n",
      "8/21 Processing Ia-SupCh_SN2009dc_10.40_.txt \n",
      "9/21 Processing Ia-SupCh_SN2009dc_5.50_.txt \n",
      "10/21 Processing Ia-SupCh_SN2009dc_-4.70_.txt \n",
      "11/21 Processing Ia-SupCh_SN2009dc_3.40_.txt \n",
      "12/21 Processing Ia-SupCh_SN2009dc_8.30_.txt \n",
      "13/21 Processing Ia-SupCh_SN2009dc_31.30_.txt \n",
      "14/21 Processing Ia-SupCh_SN2009dc_-8.50_.txt \n",
      "15/21 Processing Ia-SupCh_SN2009dc_16.50_.txt \n",
      "16/21 Processing Ia-SupCh_SN2009dc_21.50_.txt \n",
      "17/21 Processing Ia-SupCh_SN2009dc_80.30_.txt \n",
      "18/21 Processing Ia-SupCh_SN2009dc_-10.50_.txt \n",
      "19/21 Processing Ia-SupCh_SN2009dc_1.40_.txt \n",
      "20/21 Processing Ia-SupCh_SN2009dc_-9.60_.txt \n",
      "21/21 Processing Ia-SupCh_SN2009dc_164.30_.txt \n"
     ]
    }
   ],
   "source": [
    "# Set folders\n",
    "pca_folder = './PCA_ready/'\n",
    "files = glob('./new_spectra/*.txt' )\n",
    "pca_ready_save = pca_folder + 'PCAReady.%s.txt' %extension\n",
    "classification_list = pca_folder + 'classlist.%s.txt' %extension\n",
    "\n",
    "# Create the PCAReady folder if it doesn't exist\n",
    "if os.path.isdir(pca_folder) == False:\n",
    "    print(f'Creating {pca_folder}\\n')\n",
    "    os.mkdir(pca_folder)\n",
    "    \n",
    "main=[]\n",
    "lab =[]\n",
    "count =0\n",
    "for f in files:\n",
    "    count  +=1\n",
    "\n",
    "    base = os.path.basename(f)\n",
    "    print('%s/%s Processing %s ' %(count,len(files),base))\n",
    "    \n",
    "    x0, y0 = np.loadtxt(f,unpack=True,usecols=(0,1))\n",
    "    \n",
    "    if np.all(x0[1:] >= x0[:-1], axis=0) != False:\n",
    "            \n",
    "        # this shouldn't process the spectra, instead we'll pass this to\n",
    "        # the wavelength range checker next and then process the spectrum\n",
    "        x,y = x0, y0 \n",
    "\n",
    "        for z in z_range:\n",
    "            x_z = x0 * (1 + z)\n",
    "            \n",
    "            if (x_z[0] < target_wavelength_range[0] - 50) and (x_z[-1] > target_wavelength_range[1] + 50):\n",
    "                \n",
    "                # cut extraneous stuff\n",
    "                lowcut = 0\n",
    "                hicut = np.argmin(abs( x_z - (target_wavelength_range[1] + 50)) )\n",
    "                \n",
    "                x_z = x_z[lowcut:hicut]\n",
    "                y_z = y0[lowcut:hicut]\n",
    "                \n",
    "                x_z, y = ProcessSpectra(x = x_z, y = y_z ,wave_bins=8)\n",
    "                \n",
    "\n",
    "                if str(min(y))[0] in '0123456789':\n",
    "                    \n",
    "                    main.append(y)\n",
    "                    lab.append('%.3f_%s'%(z,base))\n",
    "                else:\n",
    "                    print(base, 'NaN detected',str(min(y))[0], z)\n",
    "                    \n",
    "                # if reguired uncomment to save the individual spectra    \n",
    "                #m=list(zip(x_z,y))\n",
    "                #np.savetxt('/Users/Si/Documents/searn/SupernovaClassifier/processedspectra/%.3f_%s'%(z,base),m,fmt=\"%s\")\n",
    "\n",
    "if save:\n",
    "    np.savetxt(pca_ready_save,main,fmt=\"%s\")  \n",
    "    np.savetxt(classification_list,lab,\"%s\")  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finally, concatenate the PCAReady and classlist files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicates found, removing\n",
      "\n",
      "No new objects to add.\n"
     ]
    }
   ],
   "source": [
    "def join_PCA(ref_PCAReady, ref_classlist, new_PCAReady, new_classlist, save_location = save_location, ext = ext):\n",
    "\n",
    "\n",
    "    a1 = np.loadtxt(ref_PCAReady)\n",
    "    c1 = np.loadtxt(ref_classlist, dtype = 'str')\n",
    "\n",
    "    a2 = np.loadtxt(new_PCAReady)\n",
    "    c2 = np.loadtxt(new_classlist, dtype = 'str')\n",
    "    \n",
    "    # We don't want duplicate items so we'll remove them\n",
    "    duplicate_indices = [idx for idx, spec in enumerate(c2) if spec in set(c1)] \n",
    "    \n",
    "    if len(duplicate_indices) > 0:\n",
    "        print(f'Duplicate spectra found, removing\\n')\n",
    "        a2 = np.delete(a2, duplicate_indices)\n",
    "        c2 = np.delete(c2, duplicate_indices)\n",
    "\n",
    "    \n",
    "    # if there are new objects to add, then do so\n",
    "    if len(c2) > 0:\n",
    "        print(f'Concatenating arrays...\\n')\n",
    "        a3 = np.concatenate( (a1, a2))\n",
    "        c3 = np.concatenate( (c1, c2) )\n",
    "        \n",
    "        print(f'Saving PCAReady.{ext}.txt and classlist.{ext}.txt' )\n",
    "        np.savetxt(f'{final_save_folder}/PCAReady.{ext}.txt', a3, fmt=\"%s\")\n",
    "        np.savetxt(f'{final_save_folder}/classlist.{ext}.txt', c3, fmt=\"%s\")\n",
    "        \n",
    "    else:\n",
    "        print('No new objects to add.')\n",
    "    \n",
    "join_PCA(ref_PCA, ref_classlist, pca_ready_save, classification_list)    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
